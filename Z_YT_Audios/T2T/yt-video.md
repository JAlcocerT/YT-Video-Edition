Learn how to monitor LLMs workload like a Pro.

We are going to use the NetData, together with the Ollama project, and we are going to SelfHost it with Docker. Then, we will see how our infrastructure is doing when we are utilizing our local LLMs.

Feel free to deploy this at home, or at the cloud - same process applies.


ğŸ”—ğŸ”—ğŸ”— Stack to deploy NetData: https://fossengineer.com/selfhosting-server-monitoring-with-netdata-and-docker/

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

ğŸ’» Used During The Video
LLM used: https://ollama.ai/library/mistral
NetData Docker Image ğŸ‹: https://hub.docker.com/r/netdata/netdata


ğŸŒŸ Resources you might be Interested ğŸŒŸ

* https://fossengineer.com/tags/gen-ai/
* SelfHost NGINX to provide https to Ollama: https://fossengineer.com/selfhosting-nginx-proxy-manager-docker/

* LLama-Index (Pypi): https://pypi.org/project/llama-index/
* Ollama + LogSec: https://fossengineer.com/selfhosting-logseq/

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

ğŸ‘‰ What Software have I used during the video?

It is all Free Software that you can install in Windows/Mac/Linux:

Docker: https://docs.docker.com/get-docker/
Portainer to manage the containers with UI: https://fossengineer.com/selfhosting-portainer-docker/
VSCodium to create the Dockerfile: https://vscodium.com/
OBS Studio to record screen: https://jalcocert.github.io/Linux/docs/nix/fav-apps/#dev--content

ğŸ“š Programming Books & Merch ğŸ“š
ğŸ The Python Bible Book: https://www.neuralnine.com/books/
ğŸ’» The Algorithm Bible Book: https://www.neuralnine.com/books/
ğŸ‘• Programming Merch: https://www.neuralnine.com/shop

ğŸŒ Social Media & Contact ğŸŒ 
ğŸ“± Website: https://www.neuralnine.com/
ğŸ“· Instagram:   / neuralnine  
ğŸ¦ Twitter:   / neuralnine  
ğŸ¤µ LinkedIn:   / neuralnine  
ğŸ“ GitHub: https://github.com/NeuralNine 
ğŸ™ Discord:   / discord  

ğŸµ Outro Music From: https://www.bensound.com/
ğŸµ Audio created by OpenAI API - onyx, TTS1 Model.